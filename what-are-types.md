I work at [HoTT and Dependent Types Group](https://research.jetbrains.org/groups/group-for-dependent-types-and-hott) at [JetBrains Research](https://research.jetbrains.org/). We study particular kind of type systems and their applications in programming languages and pure mathematics. This article is an attempt to explain our field to an interested programmer. I assume our intended reader to have some experience with a low-level programming language like C, a “strongly” typed object-oriented language supporting generics like Java or C#, and having seen some functional programming elements, perhaps in a language like Clojure, Scala or F#. Proficiency in strictly typed purely functional programming languages like Haskell or fluency in advanced math is _not_ assumed.

Types are there to classify “range” of variables and parameters in two classes of formal languages: programming languages and mathematical languages used for writing down theorems and proofs. Our groups is works in both directions:
– We develop one of the leading interactive theorem provers called [Arend](https://arend-lang.github.io/) and its respective language.
— We are working on type system embracing complex computational behaviours including concurrency and nondeterminism.

History of type theory is therefore twofold, types were first introduced and studied by logicians and proof theorists, most notably Bertrand Russell between 1902 and 1908 for the family of formal languages for his Principia Mathematica project of codifying basic mathematics, Alonzo Church around 1935 for his proof that first order logic is in general undecidable and Kurt Gödel between 1944 and 1958 for his proof of relative consistency of arithmetics. Types were rediscovered by programming language designers in late 1950s, but the type systems used for programming languages were rudimentary and incomplete. Moreover, they remain so except for a handful of rarely used mostly academic programming languages.

Type declarations were used only by compilers to find out what registers/how many memory cells to use for which variables, and which operations are allowed on which variables. You don't need a complex type system for that: under the hood all variables were bit strings of fixed length. Early programming languages even had a fixed number of data types directly corresponding to the hardware architecture of underlying systems, say `byte`, `int16`, `int32`, `real32`, `real64` and `pointer`. In programming languages like C++, Java, C# and alike, you have complex type systems allowing for both domain-specific data types (say, `Date` or `Color`) and custom containers like `List<SomeType>`, `BitTree<SomeType>`, `Collection<SomeType>` and `Map<KeyType, ValueType>`, but these type systems are still incomplete and “pegged” onto some fixed internal representation of values rather than having a standalone meaning. Incompleteness refers to the fact that sometimes you need to forcibly “cast” values between types to write perfectly sensible programs. Such types only annotate variables facilitating some syntactic sugar and a few very weak correctness guarantees checkable in compile time, while being a leaky abstraction "pegged" upon the true operational semantics of their respective programming language. Type systems we study are _not_ of that kind.
